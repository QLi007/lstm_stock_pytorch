{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "9708e5cd", "cell_type": "markdown", "source": "\n    # LSTM Stock Prediction with Robust Sequential Validation\n    \n    **Features:**\n    * Clone repository and set up environment\n    * Download and preprocess stock data from Yahoo Finance\n    * Run LSTM model training with advanced loss functions\n    * Compare with baseline strategies\n    * Sequential walk-forward backtesting (without data leakage)\n    * Market regime analysis and performance visualization\n    * Bootstrapped validation for robustness testing\n    ", "metadata": {}}, {"id": "f4b24c47", "cell_type": "markdown", "source": "## Environment Setup", "metadata": {}}, {"id": "1be05d0d", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Install required packages\n    !pip install yfinance pandas-ta scikit-learn scipy tensorflow matplotlib seaborn tqdm\n    \n    # Clone the repository\n    !git clone https://github.com/QLi007/lstm_stock_pytorch.git\n    %cd lstm_stock_pytorch\n    \n    # Install requirements\n    !pip install -r requirements.txt\n    ", "outputs": []}, {"id": "07859fed", "cell_type": "markdown", "source": "## Download Stock Data from Yahoo Finance", "metadata": {}}, {"id": "666f4495", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    import os\n    import yfinance as yf\n    import pandas as pd\n    import pandas_ta as ta\n    import numpy as np\n    from datetime import datetime, timedelta\n    \n    # Create data directory if it doesn't exist\n    os.makedirs('data', exist_ok=True)\n    \n    # Define stock tickers to download (you can change these)\n    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n    \n    # Set date range for 5 years of data\n    end_date = datetime.now()\n    start_date = end_date - timedelta(days=5*365)\n    \n    # Download data for each ticker\n    for ticker in tickers:\n        print(f\"Downloading {ticker} data...\")\n        data = yf.download(ticker, start=start_date, end=end_date)\n        \n        # Rename columns to lowercase\n        data.columns = [col.lower() for col in data.columns]\n        \n        # Reset index to make date a column\n        data = data.reset_index()\n        \n        # Add technical indicators\n        # Moving averages\n        for period in [5, 10, 20, 34, 60, 120, 200]:\n            data[f'MA_{period}'] = data['close'].rolling(window=period).mean()\n            data[f'price_to_MA_{period}'] = data['close'] / data[f'MA_{period}'] - 1\n        \n        # RSI\n        for period in [6, 14, 28]:\n            data[f'RSI_{period}'] = ta.rsi(data['close'], length=period)\n        \n        # MACD\n        macd = ta.macd(data['close'])\n        data = pd.concat([data, macd], axis=1)\n        \n        # Bollinger Bands\n        bbands = ta.bbands(data['close'])\n        data = pd.concat([data, bbands], axis=1)\n        \n        # Add future returns for target\n        for days in [1, 5, 10, 20]:\n            data[f'future_{days}d_return'] = data['close'].pct_change(days).shift(-days)\n        \n        # Add previous day's close for features\n        data['prev_close'] = data['close'].shift(1)\n        \n        # Add 1-day returns\n        data['return_1d'] = data['close'].pct_change(1)\n        \n        # Volatility\n        for period in [10, 20, 60]:\n            data[f'volatility_{period}'] = data['return_1d'].rolling(window=period).std()\n        \n        # Volume indicators\n        data['volume_ma10'] = data['volume'].rolling(window=10).mean()\n        data['volume_ratio'] = data['volume'] / data['volume_ma10']\n        \n        # Williams %R\n        data['Williams_%R_14'] = ta.willr(data['high'], data['low'], data['close'])\n        \n        # Save to CSV\n        csv_path = f\"data/{ticker.lower()}.csv\"\n        data.to_csv(csv_path, index=False)\n        print(f\"Saved to {csv_path}, shape: {data.shape}\")\n    \n    # Create a combined dataset (optional)\n    print(\"Creating combined dataset...\")\n    combined_data = pd.DataFrame()\n    \n    for ticker in tickers:\n        ticker_data = pd.read_csv(f\"data/{ticker.lower()}.csv\")\n        ticker_data['ticker'] = ticker\n        \n        if len(combined_data) == 0:\n            combined_data = ticker_data\n        else:\n            combined_data = pd.concat([combined_data, ticker_data])\n    \n    # Save combined dataset\n    combined_csv_path = \"data/combined_stocks.csv\"\n    combined_data.to_csv(combined_csv_path, index=False)\n    print(f\"Combined dataset saved to {combined_csv_path}, shape: {combined_data.shape}\")\n    \n    # List available CSV files\n    print(\"\\nAvailable data files:\")\n    !ls -l data/*.csv\n    ", "outputs": []}, {"id": "6cdacbbb", "cell_type": "markdown", "source": "## Update Configuration File", "metadata": {}}, {"id": "e9dd15eb", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    import yaml\n    import os\n    \n    # List available CSV files\n    csv_files = [f for f in os.listdir('data') if f.endswith('.csv')]\n    print(\"Available data files:\")\n    for i, file in enumerate(csv_files):\n        print(f\"{i}: {file}\")\n    \n    # Choose which file to use (default to the first one)\n    chosen_idx = 0  # Change this to use a different file\n    chosen_file = csv_files[chosen_idx]\n    data_path = os.path.join('data', chosen_file)\n    \n    print(f\"\\nUsing data file: {data_path}\")\n    \n    # Load the default config\n    config_path = 'configs/default.yaml'\n    with open(config_path) as f:\n        config = yaml.safe_load(f)\n    \n    # Update the data path\n    config['data']['path'] = data_path\n    \n    # Save back to a new config file\n    custom_config_path = 'configs/lstm_config.yaml'\n    with open(custom_config_path, 'w') as f:\n        yaml.dump(config, f, default_flow_style=False)\n    \n    print(f\"Updated configuration saved to {custom_config_path}\")\n    \n    # Display the updated config\n    print(\"\\nConfiguration:\")\n    !cat {custom_config_path}\n    ", "outputs": []}, {"id": "3b217316", "cell_type": "markdown", "source": "## Explore Project Structure", "metadata": {}}, {"id": "db8a5b67", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # List important directories and files\n    print(\"Project structure:\\n\")\n    !ls -la\n    \n    print(\"\\n\\nSource code files:\")\n    !ls -la src/\n    \n    print(\"\\n\\nModel files:\")\n    !ls -la src/model/\n    \n    print(\"\\n\\nData processing files:\")\n    !ls -la src/data/\n    \n    print(\"\\n\\nBaseline strategy files:\")\n    !ls -la src/baselines/\n    \n    print(\"\\n\\nConfiguration files:\")\n    !ls -la configs/\n    ", "outputs": []}, {"id": "3d78c4ad", "cell_type": "markdown", "source": "## Run Quick Test (Dry Run)", "metadata": {}}, {"id": "8340fb1f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Run a quick test with fewer epochs\n    !python -m src.train --config configs/lstm_config.yaml --dry-run\n    ", "outputs": []}, {"id": "6883dbe6", "cell_type": "markdown", "source": "## Full Model Training", "metadata": {}}, {"id": "d94981be", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Run full training with Kelly-based loss function\n    !python -m src.train --config configs/lstm_config.yaml --save-model --model-path models/lstm_model.pt --loss-function kelly\n    ", "outputs": []}, {"id": "15a17a39", "cell_type": "markdown", "source": "\n    ## Sequential Validation (Walk-Forward Testing)\n    \n    This is a critical step to ensure the model performs well in real-time conditions without data leakage. The sequential validation:\n    \n    1. Processes data point by point, exactly as in real trading\n    2. Ensures no future information is used in making predictions\n    3. Analyzes performance across different market regimes\n    ", "metadata": {}}, {"id": "e0ee2c89", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Run sequential validation\n    !python -m src.train --config configs/lstm_config.yaml --model-path models/lstm_model.pt --sequential-validation\n    \n    # Display the generated plots\n    import matplotlib.pyplot as plt\n    from IPython.display import display, Image\n    import glob\n    \n    # Equity curve\n    display(Image(filename='logs/sequential/equity_curve.png'))\n    \n    # Positions over time\n    display(Image(filename='logs/sequential/positions.png'))\n    \n    # Position vs Future Return\n    display(Image(filename='logs/sequential/position_vs_return.png'))\n    \n    # Return distribution\n    display(Image(filename='logs/sequential/return_distribution.png'))\n    ", "outputs": []}, {"id": "340d559c", "cell_type": "markdown", "source": "\n    ## Market Regime Analysis\n    \n    Analyzing how the model performs across different market conditions:\n    \n    * Bull markets (uptrend)\n    * Bear markets (downtrend)\n    * High volatility periods\n    * Sideways/ranging markets\n    ", "metadata": {}}, {"id": "57004ffc", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Display regime analysis plots\n    regime_plots = glob.glob('logs/regimes/*.png')\n    \n    for plot in regime_plots:\n        print(f\"\\n{os.path.basename(plot)}\")\n        display(Image(filename=plot))\n    \n    # Read and display the sequential validation results\n    import pandas as pd\n    \n    results = pd.read_csv('logs/sequential/sequential_results.csv')\n    print(\"Performance metrics:\")\n    print(f\"Total return: {results['total_return'].iloc[0]:.2%}\")\n    print(f\"Sharpe ratio: {results['sharpe_ratio'].iloc[0]:.2f}\")\n    print(f\"Max drawdown: {results['max_drawdown'].iloc[0]:.2%}\")\n    print(f\"Win rate: {results['win_rate'].iloc[0]:.2%}\")\n    ", "outputs": []}, {"id": "5f96c3c0", "cell_type": "markdown", "source": "\n    ## Bootstrap Validation for Robustness Testing\n    \n    Bootstrap validation helps assess model robustness by:\n    \n    * Running multiple validation simulations on resampled data\n    * Establishing confidence intervals for performance metrics\n    * Identifying how consistent the model performance is\n    ", "metadata": {}}, {"id": "0b5066c9", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Run bootstrap validation with 20 iterations\n    !python -m src.train --config configs/lstm_config.yaml --model-path models/lstm_model.pt --sequential-validation --bootstrap --bootstrap-iterations 20\n    \n    # Display bootstrap plots\n    bootstrap_plots = glob.glob('logs/bootstrap/*.png')\n    \n    for plot in bootstrap_plots:\n        if 'iteration' not in plot:  # Skip individual iteration plots\n            print(f\"\\n{os.path.basename(plot)}\")\n            display(Image(filename=plot))\n    \n    # Read and display bootstrap statistics\n    bootstrap_stats = pd.read_csv('logs/bootstrap/bootstrap_stats.csv', index_col=0)\n    print(\"\\nBootstrap Statistics:\")\n    display(bootstrap_stats)\n    ", "outputs": []}, {"id": "eaaf42c8", "cell_type": "markdown", "source": "## Advanced Strategy Comparison", "metadata": {}}, {"id": "0a0fb0c0", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n    # Compare LSTM model against traditional strategies\n    !python -m src.evaluate --config configs/lstm_config.yaml --model-path models/lstm_model.pt --strategies \"buy_hold,moving_average,rsi,macd\" --plot\n    \n    # Display comparison plots\n    strategy_plots = glob.glob('logs/strategy_comparison/*.png')\n    \n    for plot in strategy_plots:\n        print(f\"\\n{os.path.basename(plot)}\")\n        display(Image(filename=plot))\n    ", "outputs": []}]}